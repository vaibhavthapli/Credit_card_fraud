{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115966.0</td>\n",
       "      <td>-2.163081</td>\n",
       "      <td>1.711095</td>\n",
       "      <td>-0.525640</td>\n",
       "      <td>0.194081</td>\n",
       "      <td>-1.029697</td>\n",
       "      <td>0.136284</td>\n",
       "      <td>-1.357683</td>\n",
       "      <td>1.879366</td>\n",
       "      <td>-0.597058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452132</td>\n",
       "      <td>0.806195</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>0.678795</td>\n",
       "      <td>-0.258603</td>\n",
       "      <td>0.712588</td>\n",
       "      <td>-0.713277</td>\n",
       "      <td>-0.182202</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131891.0</td>\n",
       "      <td>1.804736</td>\n",
       "      <td>-1.271865</td>\n",
       "      <td>-2.956493</td>\n",
       "      <td>-0.353553</td>\n",
       "      <td>0.130945</td>\n",
       "      <td>-1.199074</td>\n",
       "      <td>0.740902</td>\n",
       "      <td>-0.554545</td>\n",
       "      <td>-0.900114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.045037</td>\n",
       "      <td>-0.290662</td>\n",
       "      <td>0.508793</td>\n",
       "      <td>0.410006</td>\n",
       "      <td>0.982054</td>\n",
       "      <td>-0.186231</td>\n",
       "      <td>-0.048551</td>\n",
       "      <td>258.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136997.0</td>\n",
       "      <td>1.963918</td>\n",
       "      <td>-0.131719</td>\n",
       "      <td>-0.888165</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.498022</td>\n",
       "      <td>-0.042393</td>\n",
       "      <td>-0.097297</td>\n",
       "      <td>0.176875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394307</td>\n",
       "      <td>-1.202584</td>\n",
       "      <td>0.456352</td>\n",
       "      <td>-0.517482</td>\n",
       "      <td>-0.640613</td>\n",
       "      <td>-0.268896</td>\n",
       "      <td>-0.047348</td>\n",
       "      <td>-0.052698</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152773.0</td>\n",
       "      <td>-0.190464</td>\n",
       "      <td>1.021640</td>\n",
       "      <td>-0.804140</td>\n",
       "      <td>-0.132867</td>\n",
       "      <td>0.385977</td>\n",
       "      <td>-1.142098</td>\n",
       "      <td>0.469435</td>\n",
       "      <td>0.331246</td>\n",
       "      <td>-0.393996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410755</td>\n",
       "      <td>1.062838</td>\n",
       "      <td>-0.117616</td>\n",
       "      <td>-0.082971</td>\n",
       "      <td>-0.454951</td>\n",
       "      <td>-0.171760</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>0.041254</td>\n",
       "      <td>14.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150005.0</td>\n",
       "      <td>2.008214</td>\n",
       "      <td>-0.280217</td>\n",
       "      <td>-0.465804</td>\n",
       "      <td>0.308430</td>\n",
       "      <td>-0.353631</td>\n",
       "      <td>-0.178018</td>\n",
       "      <td>-0.527558</td>\n",
       "      <td>0.035737</td>\n",
       "      <td>1.260708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191681</td>\n",
       "      <td>-0.409743</td>\n",
       "      <td>0.404496</td>\n",
       "      <td>0.559148</td>\n",
       "      <td>-0.401731</td>\n",
       "      <td>-0.644915</td>\n",
       "      <td>0.035181</td>\n",
       "      <td>-0.026480</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  115966.0 -2.163081  1.711095 -0.525640  0.194081 -1.029697  0.136284   \n",
       "1  131891.0  1.804736 -1.271865 -2.956493 -0.353553  0.130945 -1.199074   \n",
       "2  136997.0  1.963918 -0.131719 -0.888165  0.259542 -0.001108 -0.498022   \n",
       "3  152773.0 -0.190464  1.021640 -0.804140 -0.132867  0.385977 -1.142098   \n",
       "4  150005.0  2.008214 -0.280217 -0.465804  0.308430 -0.353631 -0.178018   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -1.357683  1.879366 -0.597058  ...  0.452132  0.806195 -0.021418  0.678795   \n",
       "1  0.740902 -0.554545 -0.900114  ... -0.000194 -0.045037 -0.290662  0.508793   \n",
       "2 -0.042393 -0.097297  0.176875  ... -0.394307 -1.202584  0.456352 -0.517482   \n",
       "3  0.469435  0.331246 -0.393996  ...  0.410755  1.062838 -0.117616 -0.082971   \n",
       "4 -0.527558  0.035737  1.260708  ... -0.191681 -0.409743  0.404496  0.559148   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.258603  0.712588 -0.713277 -0.182202    6.79      0  \n",
       "1  0.410006  0.982054 -0.186231 -0.048551  258.40      0  \n",
       "2 -0.640613 -0.268896 -0.047348 -0.052698   29.00      0  \n",
       "3 -0.454951 -0.171760  0.012971  0.041254   14.18      0  \n",
       "4 -0.401731 -0.644915  0.035181 -0.026480    0.12      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"credit.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(\"Class\",axis=\"columns\")\n",
    "Y=df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226971, 30)\n",
      "(56743, 30)\n",
      "(226971,)\n",
      "(56743,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always check before built a model is your training dataset is balanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    226592\n",
       "1       379\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's like our traninig dataset is imbalanced so first we need to balanced that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We use OverSampling to solve imbalanced traning data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import over_sampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12)\n",
    "X_train, Y_train = sm.fit_sample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(453184, 30)\n",
      "(453184,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    226592\n",
       "0    226592\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now our training data is balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      157778.000000\n",
       "V1            -0.102318\n",
       "V2             0.355017\n",
       "V3             1.472947\n",
       "V4            -0.267198\n",
       "V5             0.432963\n",
       "V6             0.864004\n",
       "V7             0.170404\n",
       "V8             0.089408\n",
       "V9             0.068169\n",
       "V10           -0.138768\n",
       "V11            0.390472\n",
       "V12            0.544438\n",
       "V13            0.521065\n",
       "V14           -0.399394\n",
       "V15           -0.007097\n",
       "V16            0.041325\n",
       "V17           -0.646902\n",
       "V18            0.810754\n",
       "V19            1.173219\n",
       "V20            0.202743\n",
       "V21            0.231805\n",
       "V22            0.980056\n",
       "V23           -0.252268\n",
       "V24            0.304315\n",
       "V25           -0.513289\n",
       "V26            0.658487\n",
       "V27           -0.008806\n",
       "V28           -0.060263\n",
       "Amount        11.500000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to shuffle our data once again.\n",
    "# for that we have to join our X_train and Y_train together\n",
    "concatenat = pd.concat([X_train, Y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157778.000000</td>\n",
       "      <td>-0.102318</td>\n",
       "      <td>0.355017</td>\n",
       "      <td>1.472947</td>\n",
       "      <td>-0.267198</td>\n",
       "      <td>0.432963</td>\n",
       "      <td>0.864004</td>\n",
       "      <td>0.170404</td>\n",
       "      <td>0.089408</td>\n",
       "      <td>0.068169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231805</td>\n",
       "      <td>0.980056</td>\n",
       "      <td>-0.252268</td>\n",
       "      <td>0.304315</td>\n",
       "      <td>-0.513289</td>\n",
       "      <td>0.658487</td>\n",
       "      <td>-0.008806</td>\n",
       "      <td>-0.060263</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70900.000000</td>\n",
       "      <td>1.233013</td>\n",
       "      <td>-0.520422</td>\n",
       "      <td>0.033394</td>\n",
       "      <td>-0.706597</td>\n",
       "      <td>-0.602408</td>\n",
       "      <td>-0.137798</td>\n",
       "      <td>-0.704692</td>\n",
       "      <td>0.100175</td>\n",
       "      <td>-1.011925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137506</td>\n",
       "      <td>0.221700</td>\n",
       "      <td>-0.070302</td>\n",
       "      <td>-0.372932</td>\n",
       "      <td>0.295588</td>\n",
       "      <td>-0.256301</td>\n",
       "      <td>0.033671</td>\n",
       "      <td>0.037965</td>\n",
       "      <td>59.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77381.000000</td>\n",
       "      <td>1.207151</td>\n",
       "      <td>-0.214659</td>\n",
       "      <td>0.873963</td>\n",
       "      <td>0.614853</td>\n",
       "      <td>-0.495640</td>\n",
       "      <td>0.637324</td>\n",
       "      <td>-0.726961</td>\n",
       "      <td>0.265679</td>\n",
       "      <td>0.986651</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122415</td>\n",
       "      <td>-0.107237</td>\n",
       "      <td>-0.038538</td>\n",
       "      <td>-0.731636</td>\n",
       "      <td>0.294839</td>\n",
       "      <td>0.399316</td>\n",
       "      <td>0.033279</td>\n",
       "      <td>0.014372</td>\n",
       "      <td>3.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122802.000000</td>\n",
       "      <td>-0.236398</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>1.184713</td>\n",
       "      <td>4.737655</td>\n",
       "      <td>0.979416</td>\n",
       "      <td>0.185857</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>-0.027505</td>\n",
       "      <td>-1.871850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255983</td>\n",
       "      <td>0.854751</td>\n",
       "      <td>-0.057445</td>\n",
       "      <td>0.093801</td>\n",
       "      <td>-0.528897</td>\n",
       "      <td>0.459252</td>\n",
       "      <td>0.216245</td>\n",
       "      <td>0.220738</td>\n",
       "      <td>22.720000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33619.000000</td>\n",
       "      <td>1.163253</td>\n",
       "      <td>-0.014139</td>\n",
       "      <td>1.272299</td>\n",
       "      <td>1.420947</td>\n",
       "      <td>-0.926893</td>\n",
       "      <td>-0.121972</td>\n",
       "      <td>-0.519157</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.977292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180902</td>\n",
       "      <td>-0.219039</td>\n",
       "      <td>0.020564</td>\n",
       "      <td>0.398989</td>\n",
       "      <td>0.448507</td>\n",
       "      <td>-0.456745</td>\n",
       "      <td>0.075666</td>\n",
       "      <td>0.035279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453179</th>\n",
       "      <td>62144.419722</td>\n",
       "      <td>-2.222882</td>\n",
       "      <td>2.126074</td>\n",
       "      <td>-3.128421</td>\n",
       "      <td>3.442500</td>\n",
       "      <td>-3.348853</td>\n",
       "      <td>0.193943</td>\n",
       "      <td>-1.683957</td>\n",
       "      <td>1.090650</td>\n",
       "      <td>-2.164823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598526</td>\n",
       "      <td>0.376840</td>\n",
       "      <td>-0.243781</td>\n",
       "      <td>-0.433650</td>\n",
       "      <td>-0.107804</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>0.522232</td>\n",
       "      <td>-0.073007</td>\n",
       "      <td>383.439813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453180</th>\n",
       "      <td>20534.941595</td>\n",
       "      <td>-15.660487</td>\n",
       "      <td>8.643150</td>\n",
       "      <td>-22.668659</td>\n",
       "      <td>11.871206</td>\n",
       "      <td>-8.982762</td>\n",
       "      <td>-2.369684</td>\n",
       "      <td>-16.455173</td>\n",
       "      <td>0.821834</td>\n",
       "      <td>-6.317482</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.351712</td>\n",
       "      <td>1.045480</td>\n",
       "      <td>1.123201</td>\n",
       "      <td>-1.042524</td>\n",
       "      <td>-0.129940</td>\n",
       "      <td>0.655189</td>\n",
       "      <td>2.139298</td>\n",
       "      <td>-1.410086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453181</th>\n",
       "      <td>168034.589157</td>\n",
       "      <td>-2.444340</td>\n",
       "      <td>-0.472410</td>\n",
       "      <td>-2.772435</td>\n",
       "      <td>1.367274</td>\n",
       "      <td>-0.329228</td>\n",
       "      <td>-0.868994</td>\n",
       "      <td>1.487789</td>\n",
       "      <td>-0.305470</td>\n",
       "      <td>-0.665766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029802</td>\n",
       "      <td>0.251212</td>\n",
       "      <td>0.127289</td>\n",
       "      <td>0.395556</td>\n",
       "      <td>-0.213896</td>\n",
       "      <td>-0.138659</td>\n",
       "      <td>0.653129</td>\n",
       "      <td>-0.153862</td>\n",
       "      <td>484.839949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453182</th>\n",
       "      <td>142739.472988</td>\n",
       "      <td>-0.371175</td>\n",
       "      <td>1.806046</td>\n",
       "      <td>-3.325165</td>\n",
       "      <td>3.566761</td>\n",
       "      <td>2.411063</td>\n",
       "      <td>-2.413755</td>\n",
       "      <td>-4.524892</td>\n",
       "      <td>-1.235140</td>\n",
       "      <td>-1.439346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426735</td>\n",
       "      <td>-0.252472</td>\n",
       "      <td>-3.902142</td>\n",
       "      <td>0.332871</td>\n",
       "      <td>-0.973055</td>\n",
       "      <td>-0.372891</td>\n",
       "      <td>0.710206</td>\n",
       "      <td>0.412249</td>\n",
       "      <td>1.650293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453183</th>\n",
       "      <td>69663.094314</td>\n",
       "      <td>0.512203</td>\n",
       "      <td>1.135434</td>\n",
       "      <td>-2.143976</td>\n",
       "      <td>2.501154</td>\n",
       "      <td>-0.433225</td>\n",
       "      <td>-1.337947</td>\n",
       "      <td>-1.070323</td>\n",
       "      <td>0.326413</td>\n",
       "      <td>-0.695457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082543</td>\n",
       "      <td>-0.646759</td>\n",
       "      <td>-0.233314</td>\n",
       "      <td>0.027378</td>\n",
       "      <td>0.643754</td>\n",
       "      <td>-0.337702</td>\n",
       "      <td>0.348758</td>\n",
       "      <td>0.251188</td>\n",
       "      <td>90.949842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>453184 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time         V1        V2         V3         V4        V5  \\\n",
       "0       157778.000000  -0.102318  0.355017   1.472947  -0.267198  0.432963   \n",
       "1        70900.000000   1.233013 -0.520422   0.033394  -0.706597 -0.602408   \n",
       "2        77381.000000   1.207151 -0.214659   0.873963   0.614853 -0.495640   \n",
       "3       122802.000000  -0.236398  0.948039   1.184713   4.737655  0.979416   \n",
       "4        33619.000000   1.163253 -0.014139   1.272299   1.420947 -0.926893   \n",
       "...               ...        ...       ...        ...        ...       ...   \n",
       "453179   62144.419722  -2.222882  2.126074  -3.128421   3.442500 -3.348853   \n",
       "453180   20534.941595 -15.660487  8.643150 -22.668659  11.871206 -8.982762   \n",
       "453181  168034.589157  -2.444340 -0.472410  -2.772435   1.367274 -0.329228   \n",
       "453182  142739.472988  -0.371175  1.806046  -3.325165   3.566761  2.411063   \n",
       "453183   69663.094314   0.512203  1.135434  -2.143976   2.501154 -0.433225   \n",
       "\n",
       "              V6         V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.864004   0.170404  0.089408  0.068169  ...  0.231805  0.980056   \n",
       "1      -0.137798  -0.704692  0.100175 -1.011925  ...  0.137506  0.221700   \n",
       "2       0.637324  -0.726961  0.265679  0.986651  ... -0.122415 -0.107237   \n",
       "3       0.185857   0.408900 -0.027505 -1.871850  ...  0.255983  0.854751   \n",
       "4      -0.121972  -0.519157  0.093523  0.977292  ... -0.180902 -0.219039   \n",
       "...          ...        ...       ...       ...  ...       ...       ...   \n",
       "453179  0.193943  -1.683957  1.090650 -2.164823  ...  0.598526  0.376840   \n",
       "453180 -2.369684 -16.455173  0.821834 -6.317482  ... -2.351712  1.045480   \n",
       "453181 -0.868994   1.487789 -0.305470 -0.665766  ...  0.029802  0.251212   \n",
       "453182 -2.413755  -4.524892 -1.235140 -1.439346  ... -0.426735 -0.252472   \n",
       "453183 -1.337947  -1.070323  0.326413 -0.695457  ...  0.082543 -0.646759   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  \\\n",
       "0      -0.252268  0.304315 -0.513289  0.658487 -0.008806 -0.060263   \n",
       "1      -0.070302 -0.372932  0.295588 -0.256301  0.033671  0.037965   \n",
       "2      -0.038538 -0.731636  0.294839  0.399316  0.033279  0.014372   \n",
       "3      -0.057445  0.093801 -0.528897  0.459252  0.216245  0.220738   \n",
       "4       0.020564  0.398989  0.448507 -0.456745  0.075666  0.035279   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "453179 -0.243781 -0.433650 -0.107804  0.029476  0.522232 -0.073007   \n",
       "453180  1.123201 -1.042524 -0.129940  0.655189  2.139298 -1.410086   \n",
       "453181  0.127289  0.395556 -0.213896 -0.138659  0.653129 -0.153862   \n",
       "453182 -3.902142  0.332871 -0.973055 -0.372891  0.710206  0.412249   \n",
       "453183 -0.233314  0.027378  0.643754 -0.337702  0.348758  0.251188   \n",
       "\n",
       "            Amount  Class  \n",
       "0        11.500000      0  \n",
       "1        59.900000      0  \n",
       "2         3.770000      0  \n",
       "3        22.720000      0  \n",
       "4         1.000000      0  \n",
       "...            ...    ...  \n",
       "453179  383.439813      1  \n",
       "453180    1.000000      1  \n",
       "453181  484.839949      1  \n",
       "453182    1.650293      1  \n",
       "453183   90.949842      1  \n",
       "\n",
       "[453184 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23056</th>\n",
       "      <td>78450.000000</td>\n",
       "      <td>1.345902</td>\n",
       "      <td>-0.727354</td>\n",
       "      <td>-0.055258</td>\n",
       "      <td>-0.801420</td>\n",
       "      <td>-0.394547</td>\n",
       "      <td>0.396940</td>\n",
       "      <td>-0.655002</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>-0.658044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080432</td>\n",
       "      <td>0.284864</td>\n",
       "      <td>-0.203693</td>\n",
       "      <td>-0.801062</td>\n",
       "      <td>0.679595</td>\n",
       "      <td>-0.080645</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>-0.011727</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93318</th>\n",
       "      <td>72019.000000</td>\n",
       "      <td>-1.788876</td>\n",
       "      <td>-1.859378</td>\n",
       "      <td>2.026742</td>\n",
       "      <td>-0.226888</td>\n",
       "      <td>0.067665</td>\n",
       "      <td>-0.970044</td>\n",
       "      <td>-0.555985</td>\n",
       "      <td>0.262382</td>\n",
       "      <td>1.161360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399002</td>\n",
       "      <td>0.603280</td>\n",
       "      <td>0.637847</td>\n",
       "      <td>0.384952</td>\n",
       "      <td>-0.139771</td>\n",
       "      <td>-0.568477</td>\n",
       "      <td>0.111293</td>\n",
       "      <td>0.190594</td>\n",
       "      <td>199.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383574</th>\n",
       "      <td>128627.766994</td>\n",
       "      <td>0.965213</td>\n",
       "      <td>1.577598</td>\n",
       "      <td>-4.661300</td>\n",
       "      <td>3.679377</td>\n",
       "      <td>-0.090487</td>\n",
       "      <td>-0.870608</td>\n",
       "      <td>-2.227810</td>\n",
       "      <td>0.635635</td>\n",
       "      <td>-0.925183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519091</td>\n",
       "      <td>0.379933</td>\n",
       "      <td>-0.218714</td>\n",
       "      <td>0.287818</td>\n",
       "      <td>0.540852</td>\n",
       "      <td>-0.167767</td>\n",
       "      <td>0.610626</td>\n",
       "      <td>0.309138</td>\n",
       "      <td>54.742845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111431</th>\n",
       "      <td>114702.000000</td>\n",
       "      <td>-1.300980</td>\n",
       "      <td>0.210085</td>\n",
       "      <td>0.724790</td>\n",
       "      <td>-0.858554</td>\n",
       "      <td>1.923591</td>\n",
       "      <td>-1.157871</td>\n",
       "      <td>1.025614</td>\n",
       "      <td>-0.113149</td>\n",
       "      <td>-0.937659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>-0.011689</td>\n",
       "      <td>-0.471942</td>\n",
       "      <td>-0.285402</td>\n",
       "      <td>1.146795</td>\n",
       "      <td>0.417958</td>\n",
       "      <td>-0.108980</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>13.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167848</th>\n",
       "      <td>96113.000000</td>\n",
       "      <td>0.141591</td>\n",
       "      <td>1.084148</td>\n",
       "      <td>-0.319930</td>\n",
       "      <td>-0.352796</td>\n",
       "      <td>1.002843</td>\n",
       "      <td>-0.752169</td>\n",
       "      <td>0.834841</td>\n",
       "      <td>-0.152249</td>\n",
       "      <td>1.329042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503435</td>\n",
       "      <td>-1.087611</td>\n",
       "      <td>0.106978</td>\n",
       "      <td>0.396590</td>\n",
       "      <td>-0.446574</td>\n",
       "      <td>0.082246</td>\n",
       "      <td>0.190744</td>\n",
       "      <td>0.076131</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time        V1        V2        V3        V4        V5  \\\n",
       "23056    78450.000000  1.345902 -0.727354 -0.055258 -0.801420 -0.394547   \n",
       "93318    72019.000000 -1.788876 -1.859378  2.026742 -0.226888  0.067665   \n",
       "383574  128627.766994  0.965213  1.577598 -4.661300  3.679377 -0.090487   \n",
       "111431  114702.000000 -1.300980  0.210085  0.724790 -0.858554  1.923591   \n",
       "167848   96113.000000  0.141591  1.084148 -0.319930 -0.352796  1.002843   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "23056   0.396940 -0.655002  0.148893 -0.658044  ...  0.080432  0.284864   \n",
       "93318  -0.970044 -0.555985  0.262382  1.161360  ...  0.399002  0.603280   \n",
       "383574 -0.870608 -2.227810  0.635635 -0.925183  ...  0.519091  0.379933   \n",
       "111431 -1.157871  1.025614 -0.113149 -0.937659  ...  0.074928 -0.011689   \n",
       "167848 -0.752169  0.834841 -0.152249  1.329042  ... -0.503435 -1.087611   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  \\\n",
       "23056  -0.203693 -0.801062  0.679595 -0.080645  0.011503 -0.011727   \n",
       "93318   0.637847  0.384952 -0.139771 -0.568477  0.111293  0.190594   \n",
       "383574 -0.218714  0.287818  0.540852 -0.167767  0.610626  0.309138   \n",
       "111431 -0.471942 -0.285402  1.146795  0.417958 -0.108980  0.025469   \n",
       "167848  0.106978  0.396590 -0.446574  0.082246  0.190744  0.076131   \n",
       "\n",
       "            Amount  Class  \n",
       "23056    27.000000      0  \n",
       "93318   199.100000      0  \n",
       "383574   54.742845      1  \n",
       "111431   13.350000      0  \n",
       "167848    4.490000      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now shuffle\n",
    "data = shuffle(concatenat)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453184, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data.duplicated().sum()) # we don't have any dublicate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split again\n",
    "X_train = data.drop(\"Class\",axis=\"columns\")\n",
    "Y_train = data[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = Y_train.to_numpy()\n",
    "y_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine best model for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range (hp.Int(\"num_layers\",2, 10)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_'+ str(i),\n",
    "                                        min_value=20,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir/helloworld/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir/helloworld/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 11\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 10, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_5 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_6 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_7 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_8 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "Results summary\n",
      "Results in my_dir/helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 9\n",
      "units_0: 20\n",
      "units_1: 20\n",
      "learning_rate: 0.001\n",
      "units_2: 20\n",
      "units_3: 20\n",
      "units_4: 20\n",
      "units_5: 20\n",
      "units_6: 20\n",
      "units_7: 20\n",
      "units_8: 20\n",
      "Score: 0.8137442072232565\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 9\n",
      "units_0: 340\n",
      "units_1: 244\n",
      "learning_rate: 0.001\n",
      "units_2: 276\n",
      "units_3: 436\n",
      "units_4: 244\n",
      "units_5: 500\n",
      "units_6: 500\n",
      "units_7: 244\n",
      "units_8: 404\n",
      "Score: 0.5739745696385702\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 308\n",
      "units_1: 212\n",
      "learning_rate: 0.001\n",
      "units_2: 276\n",
      "units_3: 212\n",
      "units_4: 276\n",
      "units_5: 308\n",
      "units_6: 276\n",
      "units_7: 500\n",
      "units_8: 116\n",
      "Score: 0.5006895661354065\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 404\n",
      "units_1: 468\n",
      "learning_rate: 0.001\n",
      "units_2: 212\n",
      "units_3: 84\n",
      "units_4: 20\n",
      "units_5: 276\n",
      "units_6: 436\n",
      "units_7: 308\n",
      "units_8: 116\n",
      "Score: 0.500678539276123\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 52\n",
      "units_1: 372\n",
      "learning_rate: 0.001\n",
      "units_2: 500\n",
      "units_3: 404\n",
      "units_4: 180\n",
      "units_5: 308\n",
      "units_6: 372\n",
      "units_7: 116\n",
      "units_8: 52\n",
      "Score: 0.500678539276123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.search_space_summary(), tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, Y_train,\n",
    "             epochs=10,\n",
    "             validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x7fcf45131910>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fcf45131fd0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fcf3f68c9d0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fcf40530af0>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fcf4046d4f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir/helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 9\n",
      "units_0: 20\n",
      "units_1: 20\n",
      "learning_rate: 0.001\n",
      "units_2: 20\n",
      "units_3: 20\n",
      "units_4: 20\n",
      "units_5: 20\n",
      "units_6: 20\n",
      "units_7: 20\n",
      "units_8: 20\n",
      "Score: 0.8137442072232565\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 9\n",
      "units_0: 340\n",
      "units_1: 244\n",
      "learning_rate: 0.001\n",
      "units_2: 276\n",
      "units_3: 436\n",
      "units_4: 244\n",
      "units_5: 500\n",
      "units_6: 500\n",
      "units_7: 244\n",
      "units_8: 404\n",
      "Score: 0.5739745696385702\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 308\n",
      "units_1: 212\n",
      "learning_rate: 0.001\n",
      "units_2: 276\n",
      "units_3: 212\n",
      "units_4: 276\n",
      "units_5: 308\n",
      "units_6: 276\n",
      "units_7: 500\n",
      "units_8: 116\n",
      "Score: 0.5006895661354065\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 404\n",
      "units_1: 468\n",
      "learning_rate: 0.001\n",
      "units_2: 212\n",
      "units_3: 84\n",
      "units_4: 20\n",
      "units_5: 276\n",
      "units_6: 436\n",
      "units_7: 308\n",
      "units_8: 116\n",
      "Score: 0.500678539276123\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 52\n",
      "units_1: 372\n",
      "learning_rate: 0.001\n",
      "units_2: 500\n",
      "units_3: 404\n",
      "units_4: 180\n",
      "units_5: 308\n",
      "units_6: 372\n",
      "units_7: 116\n",
      "units_8: 52\n",
      "Score: 0.500678539276123\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(20, activation = \"elu\", kernel_initializer= 'he_normal', input_dim = X_train.shape[1]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(30,activation = \"elu\", kernel_initializer= 'he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(40,activation = \"elu\", kernel_initializer= 'he_normal'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(10,activation = \"elu\", kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(keras.layers.Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.01,decay=1e-4),loss=\"sparse_categorical_crossentropy\",metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2833/2833 [==============================] - 7s 2ms/step - loss: 0.0518 - accuracy: 0.9814 - val_loss: 0.0217 - val_accuracy: 0.9915\n",
      "Epoch 2/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0195 - val_accuracy: 0.9932\n",
      "Epoch 3/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0071 - val_accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0048 - val_accuracy: 0.9989\n",
      "Epoch 5/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 6/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "2833/2833 [==============================] - 6s 2ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9991\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=10, validation_split= 0.2, batch_size= 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.0834551e-10],\n",
       "       [9.9998844e-01, 1.1592873e-05],\n",
       "       [1.0000000e+00, 6.7763096e-16],\n",
       "       ...,\n",
       "       [1.0000000e+00, 5.6161083e-12],\n",
       "       [1.0000000e+00, 2.1195534e-15],\n",
       "       [1.0000000e+00, 1.2965905e-09]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56649\n",
       "1       94\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_prediction= np.argmax(pred_y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56649,     0],\n",
       "       [    0,    94]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm= confusion_matrix(Y_test,Y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56540,    19],\n",
       "       [  109,    75]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm= confusion_matrix(rounded_prediction,Y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[56540    19]\n",
      " [  109    75]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['normal','fraud']\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56559\n",
      "           1       0.80      0.41      0.54       184\n",
      "\n",
      "    accuracy                           1.00     56743\n",
      "   macro avg       0.90      0.70      0.77     56743\n",
      "weighted avg       1.00      1.00      1.00     56743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rounded_prediction,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"credit.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
